{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","Targets: Above 98% test_acc with very less number of params  \n","Results:  \n","    best test_acc = 99% on 15th epoch  \n","\n","    total parameters = 7434  \n","Analysis:  It has Basic skeleton of Lighter model with Batch normalization  \n","File Link:  "],"metadata":{"id":"r_fPUCenDXKO"}},{"cell_type":"markdown","source":["# 1. Import external libraries"],"metadata":{"id":"iRTufnR1yQuf"}},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","executionInfo":{"status":"ok","timestamp":1710514994530,"user_tz":-330,"elapsed":509,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["#### Basically working model\n","#### Img Aug RandomRotation\n","#### StepLR Scheduler\n","#### Train & Test Graphs"],"metadata":{"id":"Yr67RCeG8Xc7"}},{"cell_type":"markdown","source":["# 2. Convolutional Neural Network (model) architecture"],"metadata":{"id":"lrJhILplyZZA"}},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","executionInfo":{"status":"ok","timestamp":1710514994933,"user_tz":-330,"elapsed":22,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        chan = 8\n","        adv = 16\n","        self.conv1 = nn.Conv2d(1, chan, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv2 = nn.Conv2d(chan, chan, 3)\n","        self.bn2 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(chan, chan, 3)\n","        self.bn3 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv4 = nn.Conv2d(chan, chan, 3)\n","        self.bn4 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(chan, chan, 3)\n","        self.bn5 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv6 = nn.Conv2d(chan, adv, 3)\n","        self.bn6 = nn.BatchNorm2d(num_features=adv, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv7 = nn.Conv2d(adv, adv, 3)\n","        self.conv8 = nn.Conv2d(adv, 10, 3)\n","\n","    def forward(self, x):\n","        x = self.pool1(self.bn2(F.relu(self.conv2(self.bn1(F.relu(self.conv1(x)))))))\n","        x = self.bn4(F.relu(self.conv4(self.bn3(F.relu(self.conv3(x))))))\n","        x = (F.relu(self.conv6(self.bn5(F.relu(self.conv5(x))))))\n","        x = self.conv8(self.conv7(x))\n","        #print(x.shape)\n","        x = x.view(-1, 10) # Raja ToDo Try printing shape here\n","        return F.log_softmax(x)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# 3. Display summary of model"],"metadata":{"id":"4aE6iP1Dyl1l"}},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81a38861-00dc-4543-daca-20f5b2ecce19","executionInfo":{"status":"ok","timestamp":1710514994934,"user_tz":-330,"elapsed":22,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["#!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available() #bool\n","str_gpu_cpu = \"cuda\" if use_cuda else \"cpu\" #string\n","device = torch.device(str_gpu_cpu)\n","print(\"device is \" + str_gpu_cpu)\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["device is cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              80\n","       BatchNorm2d-2            [-1, 8, 28, 28]              16\n","            Conv2d-3            [-1, 8, 26, 26]             584\n","       BatchNorm2d-4            [-1, 8, 26, 26]              16\n","         MaxPool2d-5            [-1, 8, 13, 13]               0\n","            Conv2d-6            [-1, 8, 11, 11]             584\n","       BatchNorm2d-7            [-1, 8, 11, 11]              16\n","            Conv2d-8              [-1, 8, 9, 9]             584\n","       BatchNorm2d-9              [-1, 8, 9, 9]              16\n","           Conv2d-10              [-1, 8, 7, 7]             584\n","      BatchNorm2d-11              [-1, 8, 7, 7]              16\n","           Conv2d-12             [-1, 16, 5, 5]           1,168\n","           Conv2d-13             [-1, 16, 3, 3]           2,320\n","           Conv2d-14             [-1, 10, 1, 1]           1,450\n","================================================================\n","Total params: 7,434\n","Trainable params: 7,434\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.22\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.25\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-22-96cfc22237e9>:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"]}]},{"cell_type":"markdown","source":["# 4. Preparation of dataset  "],"metadata":{"id":"aTtGaP1BytH_"}},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","executionInfo":{"status":"ok","timestamp":1710514994935,"user_tz":-330,"elapsed":17,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["\n","SEED = 1\n","torch.manual_seed(SEED)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# 5. Train and Test Functions"],"metadata":{"id":"Sy-lDNgGyzfR"}},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","executionInfo":{"status":"ok","timestamp":1710514994936,"user_tz":-330,"elapsed":17,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    correct = 0\n","    processed = 0\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        train_losses.append(loss)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'epoch={epoch} loss={loss.item()} batch_id={batch_idx}')\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        processed += len(data)\n","        train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            test_losses.append(test_loss)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\n  Test set: Average loss: {:.4f}, Test Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    test_acc.append(100. * correct / len(test_loader.dataset))\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["# 6. Run the model with a device and an optimizer"],"metadata":{"id":"OKuLqu0Jy-pW"}},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"371a82fd-860a-4356-9660-ae40594b744b","executionInfo":{"status":"ok","timestamp":1710515448103,"user_tz":-330,"elapsed":453183,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 21): #RAJA changed epochs\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)\n","\n","#With params = 3846, on 20th epoch, test accuracy = 98.98%\n","#With params = 5146, on 11th epoch, test accuracy = 99.20% [reduced afterwards]"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-22-96cfc22237e9>:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n","epoch=1 loss=0.06281910091638565 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0851, Test Accuracy: 9746/10000 (97.46%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=2 loss=0.08258814364671707 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0626, Test Accuracy: 9808/10000 (98.08%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=3 loss=0.08882034569978714 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0595, Test Accuracy: 9819/10000 (98.19%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=4 loss=0.11929761618375778 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0343, Test Accuracy: 9896/10000 (98.96%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=5 loss=0.01448079664260149 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0379, Test Accuracy: 9888/10000 (98.88%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=6 loss=0.015032381750643253 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0319, Test Accuracy: 9894/10000 (98.94%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=7 loss=0.05739087983965874 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0329, Test Accuracy: 9888/10000 (98.88%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=8 loss=0.02725963294506073 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0317, Test Accuracy: 9891/10000 (98.91%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=9 loss=0.028301233425736427 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0402, Test Accuracy: 9881/10000 (98.81%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=10 loss=0.06388691812753677 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0313, Test Accuracy: 9892/10000 (98.92%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=11 loss=0.02389061450958252 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0318, Test Accuracy: 9895/10000 (98.95%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=12 loss=0.03117281198501587 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0347, Test Accuracy: 9882/10000 (98.82%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=13 loss=0.010098260827362537 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0354, Test Accuracy: 9887/10000 (98.87%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=14 loss=0.019130082800984383 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0314, Test Accuracy: 9895/10000 (98.95%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=15 loss=0.0031795352697372437 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0322, Test Accuracy: 9909/10000 (99.09%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=16 loss=0.01860082894563675 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0345, Test Accuracy: 9901/10000 (99.01%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=17 loss=0.007029469590634108 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0320, Test Accuracy: 9896/10000 (98.96%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=18 loss=0.002605648711323738 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0345, Test Accuracy: 9902/10000 (99.02%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=19 loss=0.01065776590257883 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0315, Test Accuracy: 9901/10000 (99.01%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=20 loss=0.03852921351790428 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0375, Test Accuracy: 9891/10000 (98.91%)\n","\n"]}]},{"cell_type":"markdown","source":["Raja ToDo :\n","Try below ::\n","1. BatchNormalization\n","2. Dropout\n","3. LR scheduler\n","4. GAP"],"metadata":{"id":"Lt5WG5wSLG2P"}}]}