{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","Targets: Above 98% test_acc with very less number of params  \n","Results:  \n","    best test_acc = 99% on 14th epoch  \n","\n","    total parameters = 5114  \n","Analysis:  It has Batch normalization, Regularization,  slightly changed model and have GAP\n","File Link:  "],"metadata":{"id":"r_fPUCenDXKO"}},{"cell_type":"markdown","source":["# 1. Import external libraries"],"metadata":{"id":"iRTufnR1yQuf"}},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT"},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Basically working model\n","#### Img Aug RandomRotation\n","#### StepLR Scheduler\n","#### Train & Test Graphs"],"metadata":{"id":"Yr67RCeG8Xc7"}},{"cell_type":"markdown","source":["# 2. Convolutional Neural Network (model) architecture"],"metadata":{"id":"lrJhILplyZZA"}},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        chan = 8\n","        adv = 16\n","        self.conv1 = nn.Conv2d(1, chan, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv2 = nn.Conv2d(chan, chan, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(chan, chan, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv4 = nn.Conv2d(chan, chan, 3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(chan, chan, 3, padding=1)\n","        self.bn5 = nn.BatchNorm2d(num_features=chan, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv6 = nn.Conv2d(chan, adv, 3, padding=1)\n","        self.bn6 = nn.BatchNorm2d(num_features=adv, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        self.conv7 = nn.Conv2d(adv, 10, 3, padding=1)\n","        self.gap = nn.AvgPool2d(kernel_size=[10,10], stride=[10,10], padding=0, ceil_mode=False, count_include_pad=False)\n","\n","\n","        self.drop = nn.Dropout(0.25)\n","\n","    def forward(self, x):\n","        x = self.drop(self.pool1(self.bn2(F.relu(self.conv2(self.bn1(F.relu(self.conv1(x))))))))\n","        x = self.drop((self.bn4(F.relu(self.conv4(self.bn3(F.relu(self.conv3(x)))))))) # Raja ToDo Try removing dropout here\n","        x = (F.relu(self.conv6(self.bn5(F.relu(self.conv5(x))))))\n","        x = self.conv7(x)\n","        x = self.gap(x) # Raja ToDo Try printing shape here\n","        #print(x.shape)\n","        x = x.view(-1, 10) # Raja ToDo Try printing shape here\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Display summary of model"],"metadata":{"id":"4aE6iP1Dyl1l"}},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d43840f-399c-4e3f-bb02-8278bee7f953","executionInfo":{"status":"ok","timestamp":1710506723614,"user_tz":-330,"elapsed":726,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["#!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available() #bool\n","str_gpu_cpu = \"cuda\" if use_cuda else \"cpu\" #string\n","device = torch.device(str_gpu_cpu)\n","print(\"device is \" + str_gpu_cpu)\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device is cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              80\n","       BatchNorm2d-2            [-1, 8, 28, 28]              16\n","            Conv2d-3            [-1, 8, 28, 28]             584\n","       BatchNorm2d-4            [-1, 8, 28, 28]              16\n","         MaxPool2d-5            [-1, 8, 14, 14]               0\n","           Dropout-6            [-1, 8, 14, 14]               0\n","            Conv2d-7            [-1, 8, 14, 14]             584\n","       BatchNorm2d-8            [-1, 8, 14, 14]              16\n","            Conv2d-9            [-1, 8, 14, 14]             584\n","      BatchNorm2d-10            [-1, 8, 14, 14]              16\n","          Dropout-11            [-1, 8, 14, 14]               0\n","           Conv2d-12            [-1, 8, 14, 14]             584\n","      BatchNorm2d-13            [-1, 8, 14, 14]              16\n","           Conv2d-14           [-1, 16, 14, 14]           1,168\n","           Conv2d-15           [-1, 10, 14, 14]           1,450\n","        AvgPool2d-16             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 5,114\n","Trainable params: 5,114\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.34\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 0.36\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-e79c0a3f2c48>:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"]}]},{"cell_type":"markdown","source":["# 4. Preparation of dataset  "],"metadata":{"id":"aTtGaP1BytH_"}},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710506725147,"user_tz":-330,"elapsed":1536,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}},"outputId":"70773abf-1dc1-4222-dd44-f8cdfe7ea958"},"source":["\n","SEED = 1\n","torch.manual_seed(SEED)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 118028653.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 38875383.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 81855524.35it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 6030556.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n"]}]},{"cell_type":"markdown","source":["# 5. Train and Test Functions"],"metadata":{"id":"Sy-lDNgGyzfR"}},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH"},"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    correct = 0\n","    processed = 0\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        train_losses.append(loss)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'epoch={epoch} loss={loss.item()} batch_id={batch_idx}')\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        processed += len(data)\n","        train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            test_losses.append(test_loss)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\n  Test set: Average loss: {:.4f}, Test Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    test_acc.append(100. * correct / len(test_loader.dataset))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Run the model with a device and an optimizer"],"metadata":{"id":"OKuLqu0Jy-pW"}},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f77376e8-f3b2-4cec-a4cf-07b4dc50a70c","executionInfo":{"status":"ok","timestamp":1710507187324,"user_tz":-330,"elapsed":462180,"user":{"displayName":"raja p nitc","userId":"00071711281456970631"}}},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 21): #RAJA changed epochs\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)\n","\n","#With params = 3846, on 20th epoch, test accuracy = 98.98%\n","#With params = 5146, on 11th epoch, test accuracy = 99.20% [reduced afterwards]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-2-e79c0a3f2c48>:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n","epoch=1 loss=0.40959736704826355 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.1475, Test Accuracy: 9580/10000 (95.80%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=2 loss=0.10914165526628494 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.1418, Test Accuracy: 9577/10000 (95.77%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=3 loss=0.1423966884613037 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0640, Test Accuracy: 9806/10000 (98.06%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=4 loss=0.17856921255588531 batch_id=468: 100%|██████████| 469/469 [00:23<00:00, 19.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0835, Test Accuracy: 9762/10000 (97.62%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=5 loss=0.10008001327514648 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0563, Test Accuracy: 9822/10000 (98.22%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=6 loss=0.012663479894399643 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0482, Test Accuracy: 9861/10000 (98.61%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=7 loss=0.014356018044054508 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0610, Test Accuracy: 9814/10000 (98.14%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=8 loss=0.13134032487869263 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0406, Test Accuracy: 9875/10000 (98.75%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=9 loss=0.04432160034775734 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0433, Test Accuracy: 9858/10000 (98.58%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=10 loss=0.018496187403798103 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0425, Test Accuracy: 9866/10000 (98.66%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=11 loss=0.09922898560762405 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0431, Test Accuracy: 9867/10000 (98.67%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=12 loss=0.040880534797906876 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0384, Test Accuracy: 9874/10000 (98.74%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=13 loss=0.08200152963399887 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0422, Test Accuracy: 9874/10000 (98.74%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=14 loss=0.041293274611234665 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 24.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0339, Test Accuracy: 9900/10000 (99.00%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=15 loss=0.0449896939098835 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0392, Test Accuracy: 9882/10000 (98.82%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=16 loss=0.04255501925945282 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0394, Test Accuracy: 9874/10000 (98.74%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=17 loss=0.014386069029569626 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0339, Test Accuracy: 9893/10000 (98.93%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=18 loss=0.07272735983133316 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 23.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0293, Test Accuracy: 9903/10000 (99.03%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=19 loss=0.1599866896867752 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 24.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0350, Test Accuracy: 9895/10000 (98.95%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=20 loss=0.15257926285266876 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0383, Test Accuracy: 9884/10000 (98.84%)\n","\n"]}]},{"cell_type":"markdown","source":["Raja ToDo :\n","Try below ::\n","1. BatchNormalization\n","2. Dropout\n","3. LR scheduler\n","4. GAP"],"metadata":{"id":"Lt5WG5wSLG2P"}}]}