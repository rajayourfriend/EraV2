{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gYZ1Q26TWdx3VWhb69UgrHQjZrOtIojL","timestamp":1710503212893},{"file_id":"1zcn2TwvQG9BbCvqqrmkCmppYQjI7O8Yi","timestamp":1710134999372},{"file_id":"1HKU8-fik7Fw5E8LyEXBQCDrIVC3Kmf9Z","timestamp":1710112341819},{"file_id":"1aei3Ogwe8TUdj6sUYCT54O7a-M6Gdy1V","timestamp":1710112321069},{"file_id":"1NpKq4jQPw_Ksg4lmQTE4_iyX0OEk29u8","timestamp":1709813628740},{"file_id":"1Vjx7LfOJDP3YdER8Blir_DYvvfJHg-0n","timestamp":1709812545489},{"file_id":"1AAczjwTTAtf2LCLtQR49seR_hKbD6QtY","timestamp":1709808756153},{"file_id":"15QkHKRpw6BQb_1LyhPbRRfD2ES4z1Tws","timestamp":1709808731962},{"file_id":"1y2EvYXdh7L6heGRg1eitKYmbSeJ5MaWt","timestamp":1709768055112},{"file_id":"1IoU5EfFy7xYgwNmCrWFZEnu_7O6WZaWc","timestamp":1709768018094},{"file_id":"13qTnZ_gq-Q6uEa53iRPz_5TcXratPcKq","timestamp":1709727562896},{"file_id":"1Myg7taWSoN0OTqOoL2mwi4P-6Ue2aj3A","timestamp":1709727542048},{"file_id":"15kJ84UYrv6O3oOY47_phbF2i8xszO5ID","timestamp":1709717350062},{"file_id":"1GlGD2epB1QGwIvJHfUt_nx5B5KHOMFyg","timestamp":1709708904074},{"file_id":"1PSaEKQF6Y-L4BolE-5BRmhFAWuZN9pCP","timestamp":1709704822562},{"file_id":"1xE4PpWcK-0Px-piG_jmx5z3JJwhru1yg","timestamp":1709704811824},{"file_id":"1JYDKj4YfBVqh0eBcY92-fvY6jhzZDkiS","timestamp":1708958579028},{"file_id":"1PaCGvtQwEuTbGHiyt7DPf86DHPnhdJ-K","timestamp":1708791879106},{"file_id":"1wEJVLeUEIOG3cBTTbpnwEufnouzhhQmG","timestamp":1708773231452},{"file_id":"11w3xUhgKC2q_6GZ6hYM8wjqJ0LeF4tOC","timestamp":1708773191999},{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1708759455015}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Targets: Above 99.4% test_acc with allowed number of params  \n","Results:  \n","    test_acc =  \n","        99.40% on 13th epoch  \n","        99.42% on 18th epoch\n","\n","    total parameters = 7996  \n","Analysis:  Have very mild fluctuation in test acc from 13th epoch to 20th epoch. It has batch normalization, regularization, increased capacity, image augmentation, playing naively with learning rates.\n","File Link:  "],"metadata":{"id":"bnlN0N2FEn8O"}},{"cell_type":"markdown","source":["# 1. Import external libraries"],"metadata":{"id":"iRTufnR1yQuf"}},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT"},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Basically working model\n","#### Img Aug RandomRotation\n","#### StepLR Scheduler\n","#### Train & Test Graphs"],"metadata":{"id":"Yr67RCeG8Xc7"}},{"cell_type":"markdown","source":["# 2. Convolutional Neural Network (model) architecture"],"metadata":{"id":"lrJhILplyZZA"}},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        set1 = 8 #channels\n","        set2 = 16 #channels\n","        out = 10 #channels\n","        avg = 7 #channels\n","        drop = 0.25 #dropout\n","        mom = 0.1\n","        self.conv1 = nn.Conv2d(1, set1, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_features=set1, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.conv2 = nn.Conv2d(set1, set1, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(num_features=set1, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(set1, set2, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(num_features=set2, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.conv4 = nn.Conv2d(set2, out, 3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(out, out, 3, padding=1)\n","        self.bn5 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.conv6 = nn.Conv2d(out, out, 3, padding=1)\n","        self.bn6 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.pool3 = nn.MaxPool2d(2, 2)\n","        self.conv7 = nn.Conv2d(out, out, 3, padding=1)\n","        self.bn7 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.conv8 = nn.Conv2d(out, out, 3, padding=1)\n","        self.bn8 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","        self.conv9 = nn.Conv2d(out, out, 3)\n","        self.bn9 = nn.BatchNorm2d(num_features=out, eps=1e-05, momentum=mom, affine=True, track_running_stats=True)\n","\n","\n","        self.drop = nn.Dropout(drop)\n","        self.gap = nn.AvgPool2d(kernel_size=[avg,avg], stride=[avg,avg], padding=0, ceil_mode=False, count_include_pad=False)\n","\n","    def forward(self, x):\n","        x = self.drop(self.pool1(self.bn2(F.relu(self.conv2(self.bn1(F.relu(self.conv1(x))))))))\n","        x = self.drop(self.pool2(self.bn4(F.relu(self.conv4(self.bn3(F.relu(self.conv3(x))))))))\n","        x = self.drop(self.pool3(self.bn6(F.relu(self.conv6(self.bn5(F.relu(self.conv5(x)))))))) # ToDo Try adding MP here\n","        x = self.drop(self.bn8(F.relu(self.conv8(self.bn7(F.relu(self.conv7(x))))))) # ToDo Try adding MP here\n","        x = self.conv9(x)\n","        #x = self.gap(x) # Raja ToDo Try printing shape here\n","        #print(x.shape)\n","        x = x.view(-1, 10) # Raja ToDo Try printing shape here\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### RuntimeError: running_mean should contain 8 elements not 4\n","Implies check the bn channels, whether it matches with the ouput channel of its previous layer."],"metadata":{"id":"C9C_o3nrrqVl"}},{"cell_type":"markdown","source":["# 3. Display summary of model"],"metadata":{"id":"4aE6iP1Dyl1l"}},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710136794363,"user_tz":-330,"elapsed":5,"user":{"displayName":"naga uber","userId":"14564436681491339051"}},"outputId":"7145e7fb-eefe-4b75-aa5f-8d2f0947e67a"},"source":["#!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available() #bool\n","str_gpu_cpu = \"cuda\" if use_cuda else \"cpu\" #string\n","device = torch.device(str_gpu_cpu)\n","print(\"device is \" + str_gpu_cpu)\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device is cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              80\n","       BatchNorm2d-2            [-1, 8, 28, 28]              16\n","            Conv2d-3            [-1, 8, 28, 28]             584\n","       BatchNorm2d-4            [-1, 8, 28, 28]              16\n","         MaxPool2d-5            [-1, 8, 14, 14]               0\n","           Dropout-6            [-1, 8, 14, 14]               0\n","            Conv2d-7           [-1, 16, 14, 14]           1,168\n","       BatchNorm2d-8           [-1, 16, 14, 14]              32\n","            Conv2d-9           [-1, 10, 14, 14]           1,450\n","      BatchNorm2d-10           [-1, 10, 14, 14]              20\n","        MaxPool2d-11             [-1, 10, 7, 7]               0\n","          Dropout-12             [-1, 10, 7, 7]               0\n","           Conv2d-13             [-1, 10, 7, 7]             910\n","      BatchNorm2d-14             [-1, 10, 7, 7]              20\n","           Conv2d-15             [-1, 10, 7, 7]             910\n","      BatchNorm2d-16             [-1, 10, 7, 7]              20\n","        MaxPool2d-17             [-1, 10, 3, 3]               0\n","          Dropout-18             [-1, 10, 3, 3]               0\n","           Conv2d-19             [-1, 10, 3, 3]             910\n","      BatchNorm2d-20             [-1, 10, 3, 3]              20\n","           Conv2d-21             [-1, 10, 3, 3]             910\n","      BatchNorm2d-22             [-1, 10, 3, 3]              20\n","          Dropout-23             [-1, 10, 3, 3]               0\n","           Conv2d-24             [-1, 10, 1, 1]             910\n","================================================================\n","Total params: 7,996\n","Trainable params: 7,996\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.32\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.35\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-b82138dca7db>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"]}]},{"cell_type":"markdown","source":["# 4. Preparation of dataset  "],"metadata":{"id":"aTtGaP1BytH_"}},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH"},"source":["\n","SEED = 1\n","torch.manual_seed(SEED)\n","batch_size = 128\n","batch_size = 64\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n","                        #transforms.RandomResizedCrop(size=(28, 28), antialias=True), #Not so good\n","                        #transforms.RandomAffine(20),\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Train and Test Functions"],"metadata":{"id":"Sy-lDNgGyzfR"}},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH"},"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    correct = 0\n","    processed = 0\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        train_losses.append(loss)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'epoch={epoch} loss={loss.item()} batch_id={batch_idx}')\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        processed += len(data)\n","        train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            test_losses.append(test_loss)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\n  Test set: Average loss: {:.4f}, Test Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    test_acc.append(100. * correct / len(test_loader.dataset))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Run the model with a device and an optimizer"],"metadata":{"id":"OKuLqu0Jy-pW"}},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710137458560,"user_tz":-330,"elapsed":664201,"user":{"displayName":"naga uber","userId":"14564436681491339051"}},"outputId":"a969ffdc-6540-41c8-a473-e4a348ee4de0"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n","ep = 21\n","for epoch in range(1, ep): #RAJA changed epochs\n","    train(model, device, train_loader, optimizer, epoch)\n","    scheduler.step()\n","    test(model, device, test_loader)\n","\n","#With params = 7996, on 11th epoch, test accuracy = 99.21% with imgaug = RandomRotation only & batch_size = 128\n","#With params = 7996, on 13th epoch, test accuracy = 99.12% with imgaug = RandomRotation only & batch_size = 256\n","#With params = 7996, on 20th epoch, test accuracy = 98.9% with imgaug = RandomRotation only & batch_size = 512\n","#With params = 7996, on 17th epoch, test accuracy = 99.36% with imgaug = RandomRotation only & batch_size = 64 - Best till now\n","#With params = 7996, on 19th epoch, test accuracy = 99.24% with imgaug = RandomRotation only & batch_size = 32\n","#With params = 7996, on 10th epoch, test accuracy = 99.24% without imgaug & batch_size = 64\n","#With params = 7996, on 19th epoch, test accuracy = 99.22% with imgaug = RandomAffine & batch_size = 64\n","#With params = 7996, on 18th epoch, test accuracy = 99.12% with batch_size = 64 & imgaug = RandomRotation -6 to +6\n","#With params = 7996, on 18th epoch, test accuracy = 99.33% with batch_size = 64 & imgaug = RandomRotation -- fill = 0 & BN -- momentum=0.1\n","#With params = 7996, on 20th epoch, test accuracy = 99.33% with batch_size = 64 & imgaug = RandomRotation -- fill = 1 & BN -- momentum=0.2\n","#With params = 7996, on 19th epoch, test accuracy = 99.31% with batch_size = 64 & imgaug = RandomRotation -- fill = 1 & BN -- momentum=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/938 [00:00<?, ?it/s]<ipython-input-15-b82138dca7db>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n","epoch=1 loss=0.10871642082929611 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0641, Test Accuracy: 9791/10000 (97.91%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=2 loss=0.04936870187520981 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0466, Test Accuracy: 9845/10000 (98.45%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=3 loss=0.035974279046058655 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0344, Test Accuracy: 9887/10000 (98.87%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=4 loss=0.011785987764596939 batch_id=937: 100%|██████████| 938/938 [00:29<00:00, 32.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0347, Test Accuracy: 9891/10000 (98.91%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=5 loss=0.05689550191164017 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0280, Test Accuracy: 9909/10000 (99.09%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=6 loss=0.21364378929138184 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0364, Test Accuracy: 9884/10000 (98.84%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=7 loss=0.017721248790621758 batch_id=937: 100%|██████████| 938/938 [00:29<00:00, 31.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0226, Test Accuracy: 9928/10000 (99.28%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=8 loss=0.007784928195178509 batch_id=937: 100%|██████████| 938/938 [00:29<00:00, 31.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0211, Test Accuracy: 9931/10000 (99.31%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=9 loss=0.01979091577231884 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0202, Test Accuracy: 9937/10000 (99.37%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=10 loss=0.008847636170685291 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0206, Test Accuracy: 9935/10000 (99.35%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=11 loss=0.022868318483233452 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0207, Test Accuracy: 9932/10000 (99.32%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=12 loss=0.07394594699144363 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0195, Test Accuracy: 9938/10000 (99.38%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=13 loss=0.04175505042076111 batch_id=937: 100%|██████████| 938/938 [00:29<00:00, 31.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0192, Test Accuracy: 9940/10000 (99.40%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=14 loss=0.016942691057920456 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0193, Test Accuracy: 9942/10000 (99.42%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=15 loss=0.07329491525888443 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0192, Test Accuracy: 9941/10000 (99.41%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=16 loss=0.08100681006908417 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 31.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0192, Test Accuracy: 9939/10000 (99.39%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=17 loss=0.013149090111255646 batch_id=937: 100%|██████████| 938/938 [00:31<00:00, 30.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0193, Test Accuracy: 9940/10000 (99.40%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=18 loss=0.1555497944355011 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0191, Test Accuracy: 9942/10000 (99.42%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=19 loss=0.04657673463225365 batch_id=937: 100%|██████████| 938/938 [00:29<00:00, 31.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0192, Test Accuracy: 9939/10000 (99.39%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch=20 loss=0.06246306002140045 batch_id=937: 100%|██████████| 938/938 [00:30<00:00, 30.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Test set: Average loss: 0.0192, Test Accuracy: 9941/10000 (99.41%)\n","\n"]}]},{"cell_type":"code","source":["fig, axs = plt.subplots(2,2,figsize=(15,10))\n","axs[0, 0].plot(train_losses)\n","axs[0, 0].set_title(\"Training Loss\")\n","axs[1, 0].plot(train_acc[4000:])\n","axs[1, 0].set_title(\"Training Accuracy\")\n","axs[0, 1].plot(test_losses)\n","axs[0, 1].set_title(\"Test Loss\")\n","axs[1, 1].plot(test_acc)\n","axs[1, 1].set_title(\"Test Accuracy\")"],"metadata":{"id":"-NtdWs6P9XY3","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1710137458561,"user_tz":-330,"elapsed":63,"user":{"displayName":"naga uber","userId":"14564436681491339051"}},"outputId":"e67c8f37-9d31-4b1c-801c-455f8f2c6877"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c49f41d3cb7e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;31m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             len(x.shape) < 1):\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1000 with 4 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Raja ToDo :\n","Try below ::\n","1. BatchNormalization - Done\n","2. Dropout  - Done\n","3. LR scheduler - Done\n","4. GAP - Done"],"metadata":{"id":"0mgyQvrQTJne"}}]}